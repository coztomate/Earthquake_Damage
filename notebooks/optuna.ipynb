{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna\n",
    "\n",
    "We use optuna to find out the best hyperparameters for the model. We run it for 100 trials on a MacBook M2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import importer\n",
    "import encoder\n",
    "import cleaner\n",
    "import normalizer\n",
    "import splitter\n",
    "\n",
    "\n",
    "raw_train_values, raw_train_labels, raw_test_values = importer.import_data(directory=\"../Data\")\n",
    "fitted_enc = encoder.create_encoder(raw_train_values)\n",
    "train_data = encoder.encode(raw_train_values, fitted_enc)\n",
    "test_data = encoder.encode(raw_test_values, fitted_enc)\n",
    "train_cleaned = cleaner.clean(train_data, raw_train_labels)\n",
    "train_log, test_data = normalizer.log_transform(train_cleaned, test_data)\n",
    "train_normalized, test_data = normalizer.normalize(train_log, test_data)\n",
    "X_train, X_val, y_train, y_val = splitter.split(train_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "def Optuna(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    #change categories of y to start from 0 bc softmax likes it that way\n",
    "    y_train = y_train - 1\n",
    "    y_test = y_test - 1\n",
    "        \n",
    "    # Define an objective function for Optuna to optimize\n",
    "    def objective(trial):\n",
    "        # Define the hyperparameters to search\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 1.0),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "        }\n",
    "\n",
    "        # Create an XGBoost classifier with the suggested hyperparameters\n",
    "        clf = xgb.XGBClassifier(**params, objective='multi:softmax', num_class=3)\n",
    "\n",
    "        # Fit the classifier to the training data\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on the test data\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        # Calculate the accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Calculate the micro F1 score\n",
    "        micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
    "\n",
    "        return micro_f1  # Optimize for micro F1 score\n",
    "\n",
    "    # Create an Optuna study and optimize the objective function\n",
    "    study = optuna.create_study(direction='maximize')  # For micro F1, maximize the objective\n",
    "    study.optimize(objective, n_trials=1)  # You can adjust the number of trials\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_params = study.best_params\n",
    "    best_micro_f1 = study.best_value\n",
    "\n",
    "    print(f\"Best Hyperparameters: {best_params}\")\n",
    "    print(f\"Best Micro F1 Score: {best_micro_f1}\")\n",
    "\n",
    "    # Train a final model with the best hyperparameters\n",
    "    best_clf = xgb.XGBClassifier(**best_params, objective='multi:softmax', num_class=3)\n",
    "    best_clf.fit(X_train, y_train)\n",
    "    y_pred = best_clf.predict(X_test)\n",
    "    final_micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    final_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Final Micro F1 Score with Best Hyperparameters: {final_micro_f1}\")\n",
    "    print(f\"Final Accuracy with Best Hyperparameters: {final_accuracy}\")\n",
    "\n",
    "    # Print a classification report with precision, recall, and F1-score for each class\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report:\")\n",
    "    print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optuna(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MiniCompetition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
